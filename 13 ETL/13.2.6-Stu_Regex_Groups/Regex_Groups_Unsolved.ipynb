{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dependencies.\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Set the column width. \n",
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALICE’S ADVENTURES IN WONDERLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHAPTER I. Down the Rabbit-Hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice was beginning to get very tired of sitting by her sister on the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bank, and of having nothing to do: once or twice she had peeped into the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book her sister was reading, but it had no pictures or conversations in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       text\n",
       "0                                          ALICE’S ADVENTURES IN WONDERLAND\n",
       "1                                           CHAPTER I. Down the Rabbit-Hole\n",
       "2     Alice was beginning to get very tired of sitting by her sister on the\n",
       "3  bank, and of having nothing to do: once or twice she had peeped into the\n",
       "4   book her sister was reading, but it had no pictures or conversations in"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the Alice in Wonderland text.\n",
    "alice_file = 'Resources/alice.txt'\n",
    "\n",
    "alice_df = pd.read_csv(alice_file, sep='\\t', header=None)\n",
    "alice_df.columns = ['text']\n",
    "alice_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <td>conversations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <th>0</th>\n",
       "      <td>disappointment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <th>0</th>\n",
       "      <td>Multiplication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <th>0</th>\n",
       "      <td>hippopotamus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <th>0</th>\n",
       "      <td>inquisitively</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <th>0</th>\n",
       "      <td>conversation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <th>0</th>\n",
       "      <td>uncomfortable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <th>0</th>\n",
       "      <td>consultation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <th>0</th>\n",
       "      <td>nevertheless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <th>0</th>\n",
       "      <td>circumstances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <th>0</th>\n",
       "      <td>contemptuously</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <th>0</th>\n",
       "      <td>contradicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <th>0</th>\n",
       "      <td>thoughtfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <th>0</th>\n",
       "      <td>extraordinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <th>0</th>\n",
       "      <td>occasionally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <th>0</th>\n",
       "      <td>straightening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <th>0</th>\n",
       "      <td>triumphantly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <th>0</th>\n",
       "      <td>interrupting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <th>0</th>\n",
       "      <td>straightened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <th>0</th>\n",
       "      <td>difficulties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <th>0</th>\n",
       "      <td>affectionately</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <th>0</th>\n",
       "      <td>uncomfortably</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <th>0</th>\n",
       "      <td>thunderstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <th>0</th>\n",
       "      <td>Uglification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <th>0</th>\n",
       "      <td>explanations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <th>0</th>\n",
       "      <td>contemptuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <th>0</th>\n",
       "      <td>refreshments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <th>0</th>\n",
       "      <td>frontispiece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <th>0</th>\n",
       "      <td>accidentally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <th>0</th>\n",
       "      <td>neighbouring</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0\n",
       "     match                \n",
       "4    0       conversations\n",
       "37   0      disappointment\n",
       "235  0      Multiplication\n",
       "292  0        hippopotamus\n",
       "303  0       inquisitively\n",
       "329  0        conversation\n",
       "353  0       uncomfortable\n",
       "355  0        consultation\n",
       "578  0        nevertheless\n",
       "747  0       circumstances\n",
       "781  0      contemptuously\n",
       "851  0        contradicted\n",
       "872  0        thoughtfully\n",
       "993  0       extraordinary\n",
       "1031 0        occasionally\n",
       "1098 0       straightening\n",
       "1360 0        triumphantly\n",
       "1393 0        interrupting\n",
       "1553 0        straightened\n",
       "1613 0        difficulties\n",
       "1660 0      affectionately\n",
       "1685 0       uncomfortably\n",
       "1740 0        thunderstorm\n",
       "1842 0        Uglification\n",
       "1992 0        explanations\n",
       "2019 0        contemptuous\n",
       "2098 0        refreshments\n",
       "2106 0        frontispiece\n",
       "2275 0        accidentally\n",
       "2451 0        neighbouring"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all words with 12 or more letters.\n",
    "p = r'(\\b\\w{12}\\w*\\b)'\n",
    "words = alice_df['text'].str.extractall(p, flags=re.I).dropna()\n",
    "words = words.drop_duplicates()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "was        17\n",
       "thought    11\n",
       "said       11\n",
       "had        10\n",
       "could      10\n",
       "           ..\n",
       "added       1\n",
       "sadly       1\n",
       "quietly     1\n",
       "angrily     1\n",
       "herself     1\n",
       "Name: 0, Length: 86, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all the words that come after \"Alice\" in the text and count their frequency.\n",
    "p = r'Alice\\s(\\w+)'\n",
    "alice_df['text'].str.extractall(p, flags=re.I)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thought         11\n",
       "could           10\n",
       "looked           8\n",
       "replied          8\n",
       "began            6\n",
       "ventured         4\n",
       "hastily          4\n",
       "heard            3\n",
       "asked            3\n",
       "indignantly      3\n",
       "waited           3\n",
       "noticed          2\n",
       "remarked         2\n",
       "quite            2\n",
       "whispered        2\n",
       "cautiously       2\n",
       "guessed          2\n",
       "called           2\n",
       "again            2\n",
       "recognised       1\n",
       "thoughtfully     1\n",
       "loudly           1\n",
       "watched          1\n",
       "gently           1\n",
       "tried            1\n",
       "rather           1\n",
       "joined           1\n",
       "alone            1\n",
       "panted           1\n",
       "found            1\n",
       "timidly          1\n",
       "appeared         1\n",
       "doubtfully       1\n",
       "sharply          1\n",
       "sighed           1\n",
       "think            1\n",
       "desperately      1\n",
       "considered       1\n",
       "angrily          1\n",
       "after            1\n",
       "opened           1\n",
       "would            1\n",
       "sadly            1\n",
       "severely         1\n",
       "aloud            1\n",
       "dodged           1\n",
       "turned           1\n",
       "folded           1\n",
       "remained         1\n",
       "crouched         1\n",
       "laughed          1\n",
       "started          1\n",
       "glanced          1\n",
       "caught           1\n",
       "added            1\n",
       "quietly          1\n",
       "herself          1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all the words 5 letters or longer that come after \"Alice\" in the text and count their frequency.\n",
    "p = r'Alice\\s(\\w{5}\\w*)'\n",
    "alice_df['text'].str.extractall(p, flags=re.I)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thought         11\n",
       "could           10\n",
       "replied          8\n",
       "looked           8\n",
       "began            6\n",
       "hastily          4\n",
       "ventured         3\n",
       "asked            3\n",
       "waited           3\n",
       "indignantly      3\n",
       "heard            3\n",
       "remarked         2\n",
       "again            2\n",
       "whispered        2\n",
       "noticed          2\n",
       "guessed          2\n",
       "cautiously       2\n",
       "recognised       1\n",
       "rather           1\n",
       "tried            1\n",
       "gently           1\n",
       "venture          1\n",
       "thoughtfully     1\n",
       "joined           1\n",
       "think            1\n",
       "found            1\n",
       "appeared         1\n",
       "sighed           1\n",
       "alone            1\n",
       "doubtfully       1\n",
       "timidly          1\n",
       "panted           1\n",
       "quite            1\n",
       "watched          1\n",
       "loudly           1\n",
       "sharply          1\n",
       "desperately      1\n",
       "considered       1\n",
       "angrily          1\n",
       "after            1\n",
       "opened           1\n",
       "would            1\n",
       "sadly            1\n",
       "severely         1\n",
       "called           1\n",
       "aloud            1\n",
       "calle            1\n",
       "dodged           1\n",
       "turned           1\n",
       "folded           1\n",
       "remained         1\n",
       "crouched         1\n",
       "laughed          1\n",
       "started          1\n",
       "glanced          1\n",
       "caught           1\n",
       "added            1\n",
       "quietly          1\n",
       "herself          1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all the words 5 letters or longer that don't end in \"ly\" that come \n",
    "# after \"Alice\" in the text and count their frequency.\n",
    "p = r'Alice\\s(\\w{5}\\w*)[^ly]'\n",
    "alice_df['text'].str.extractall(p, flags=re.I)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
